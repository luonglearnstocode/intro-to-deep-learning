**Assignment notebooks from the Introduction to Deep Learning course**
* [Session01: Linear model for grading](http://nbviewer.jupyter.org/github/luonglearnstocode/intro-to-deep-learning/blob/master/session1/Session1-linear-model-for-grading.ipynb)
* [Session02: Train and use NMIST](http://nbviewer.jupyter.org/github/luonglearnstocode/intro-to-deep-learning/blob/master/session2/Session02-Train-and-use-MNIST.ipynb)
* [Session02: Fashion-MNIST dataset](http://nbviewer.jupyter.org/github/luonglearnstocode/intro-to-deep-learning/blob/master/session2/Session02-Fashion-MNIST-dataset.ipynb)
* [Session03: Boston housing with k-fold validation](http://nbviewer.jupyter.org/github/luonglearnstocode/intro-to-deep-learning/blob/master/session3/Session3-Boston-housing-with-k-fold-validation.ipynb)
* [Session03: regularization vs. dropout fashion-MNIST](http://nbviewer.jupyter.org/github/luonglearnstocode/intro-to-deep-learning/blob/master/session3/Session3-regularization-vs-dropout-fashion-MNIST.ipynb)
* [Session04: fashion MNIST with convolutional network](http://nbviewer.jupyter.org/github/luonglearnstocode/intro-to-deep-learning/blob/master/session4/Session04-fashion-MNIST-with-convolutional-network.ipynb)
* [Session04: Cifar-10](http://nbviewer.jupyter.org/github/luonglearnstocode/intro-to-deep-learning/blob/master/session4/Session04-cifar10.ipynb)
* Session04: handwritten digits and data augmentation:
	* [Training](http://nbviewer.jupyter.org/github/luonglearnstocode/intro-to-deep-learning/blob/master/session4/Session04-handwritten-digits-and-data-augmentation-training.ipynb)
	* [Testing](http://nbviewer.jupyter.org/github/luonglearnstocode/intro-to-deep-learning/blob/master/session4/Session04-handwritten-digits-and-data-augmentation-testing.ipynb)
* [Session05: reuse convolutional base](http://nbviewer.jupyter.org/github/luonglearnstocode/intro-to-deep-learning/blob/master/session5/Session05-reuse-convolutional-base.ipynb)
* [Session06: reuters newswires classification](http://nbviewer.jupyter.org/github/luonglearnstocode/intro-to-deep-learning/blob/master/session6/Session06_reuters_newswires_classification.ipynb)
* [Session07: depth-wise separable convolution](http://nbviewer.jupyter.org/github/luonglearnstocode/intro-to-deep-learning/blob/master/session7/Session07_depth_wise_separable_convolution.ipynb)
* [Session07: reuters newswire classification with 1D convolution](http://nbviewer.jupyter.org/github/luonglearnstocode/intro-to-deep-learning/blob/master/session7/Session07-reuters-newswires-classification-with-1D-convolution.ipynb)
* [Session07: RNN for recognizing sorted int sequences](http://nbviewer.jupyter.org/github/luonglearnstocode/intro-to-deep-learning/blob/master/session7/Session07_RNN_for_recognizing_sorted_int_sequences.ipynb)
* Session07: hyperparameter optimization:
	* [hyperparameter optimization](http://nbviewer.jupyter.org/github/luonglearnstocode/intro-to-deep-learning/blob/master/session7/Session07-hyperparameter-optimization.ipynb)
	* [train optimized model]
	(http://nbviewer.jupyter.org/github/luonglearnstocode/intro-to-deep-learning/blob/master/session7/Session07_hyperparameter_optimization_model.ipynb)
* [Session07: word-level text generation](http://nbviewer.jupyter.org/github/luonglearnstocode/intro-to-deep-learning/blob/master/session7/Session07_word_level_text_generation.ipynb)