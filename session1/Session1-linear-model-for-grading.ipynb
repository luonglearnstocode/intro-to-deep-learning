{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name: **Luong Nguyen**  \n",
    "Student ID: **1504210**  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Deep Learning \n",
    "\n",
    "### Session01: Linear model for grading\n",
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import the packages needed for this assignment**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# import packages\n",
    "import numpy as np\n",
    "import keras\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with np.load(\"grading.npz\") as data:\n",
    "    x = data[ 'x' ]\n",
    "    y = data[ 'y' ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explore data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x shape: (4000, 3)\n",
      "y shape: (4000,)\n",
      "An example of points from the course: [66. 27. 48.]\n",
      "And the corresponding grade: 2.0\n",
      "\n",
      "Mean of x: [74.01725 55.40175 61.82125]\n",
      "Min of x: [ 7.  0. 25.]\n",
      "Max of x: [100. 100.  98.]\n",
      "\n",
      "Mean of y: 3.03275\n",
      "Min of y: 0.0\n",
      "Max of y: 5.0\n"
     ]
    }
   ],
   "source": [
    "print(\"x shape: \" + str(x.shape))\n",
    "print(\"y shape: \" + str(y.shape))\n",
    "print(\"An example of points from the course: \" + str(x[5]))\n",
    "print(\"And the corresponding grade: \" + str(y[5]))\n",
    "print()\n",
    "\n",
    "mean_x = np.mean(x, axis=0)\n",
    "std_x = np.std(x, axis=0)\n",
    "max_x = np.max(x, axis=0)\n",
    "min_x = np.min(x, axis=0)\n",
    "print(\"Mean of x: \" + str(mean_x))\n",
    "print(\"Min of x: \" + str(min_x))\n",
    "print(\"Max of x: \" + str(max_x))\n",
    "print()\n",
    "\n",
    "mean_y = np.mean(y)\n",
    "max_y = np.max(y)\n",
    "min_y = np.min(y)\n",
    "print(\"Mean of y: \" + str(mean_y))\n",
    "print(\"Min of y: \" + str(min_y))\n",
    "print(\"Max of y: \" + str(max_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Standardize data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A standardized row data: [-0.44488305 -1.448874   -0.63900849]\n"
     ]
    }
   ],
   "source": [
    "x -= mean_x\n",
    "x /= std_x # your example x_train /= (2 * std)\n",
    "\n",
    "print(\"A standardized row data: \" + str(x[5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Split data into train and test sets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x shape: (3000, 3)\n",
      "train_y shape: (3000,)\n",
      "test_x shape: (1000, 3)\n",
      "test_y shape: (1000,)\n"
     ]
    }
   ],
   "source": [
    "# https://stackoverflow.com/questions/3674409/how-to-split-partition-a-dataset-into-training-and-test-datasets-for-e-g-cros\n",
    "indices = np.random.permutation(x.shape[0])\n",
    "m_train = 3000\n",
    "m_test = 1000\n",
    "\n",
    "train_idx, test_idx = indices[:m_train], indices[m_train:]\n",
    "train_x, test_x = x[train_idx,:], x[test_idx,:]\n",
    "train_y, test_y = y[train_idx], y[test_idx]\n",
    "\n",
    "print (\"train_x shape: \" + str(train_x.shape))\n",
    "print (\"train_y shape: \" + str(train_y.shape))\n",
    "print (\"test_x shape: \" + str(test_x.shape))\n",
    "print (\"test_y shape: \" + str(test_y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From 4000 samples, we divided randomly into a train set with 3000 samples and a test set with 1000 samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 1)                 4         \n",
      "=================================================================\n",
      "Total params: 4\n",
      "Trainable params: 4\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Dense(1, input_shape=(3,)))\n",
    "\n",
    "model.compile(loss='mse', optimizer='sgd')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(epochs, batch_size):\n",
    "    hist = model.fit(train_x, train_y, epochs=epochs, batch_size=batch_size)\n",
    "\n",
    "    prediction_test = model.predict(test_x).reshape(m_test,)\n",
    "    prediction_train = model.predict(train_x).reshape(m_train,)\n",
    "\n",
    "    print(\"\\nModel accuracy with epochs = {0}, batch_size = {1}\".format(epochs, batch_size))\n",
    "    print(\"\\ttrain accuracy: {} %\".format(np.sum(np.round(prediction_train) == train_y) / m_train * 100))\n",
    "    print(\"\\ttest accuracy: {} %\".format(np.sum(np.round(prediction_test) == test_y) / m_test * 100))\n",
    "    \n",
    "    print(\"Weight: \")\n",
    "    print(model.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "3000/3000 [==============================] - 0s 56us/step - loss: 0.1974\n",
      "Epoch 2/5\n",
      "3000/3000 [==============================] - 0s 49us/step - loss: 0.1973\n",
      "Epoch 3/5\n",
      "3000/3000 [==============================] - 0s 48us/step - loss: 0.1974\n",
      "Epoch 4/5\n",
      "3000/3000 [==============================] - 0s 52us/step - loss: 0.1973\n",
      "Epoch 5/5\n",
      "3000/3000 [==============================] - 0s 52us/step - loss: 0.1971\n",
      "\n",
      "Model accuracy with epochs = 5, batch_size = 20\n",
      "\ttrain accuracy: 78.63333333333333 %\n",
      "\ttest accuracy: 77.4 %\n",
      "Weight: \n",
      "[array([[1.3207817 ],\n",
      "       [0.31629208],\n",
      "       [0.35098863]], dtype=float32), array([3.024428], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "batch_size = 20\n",
    "\n",
    "predict(5, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "3000/3000 [==============================] - 0s 72us/step - loss: 0.1971\n",
      "Epoch 2/20\n",
      "3000/3000 [==============================] - 0s 49us/step - loss: 0.1975\n",
      "Epoch 3/20\n",
      "3000/3000 [==============================] - 0s 74us/step - loss: 0.1970\n",
      "Epoch 4/20\n",
      "3000/3000 [==============================] - 0s 63us/step - loss: 0.1974\n",
      "Epoch 5/20\n",
      "3000/3000 [==============================] - 0s 62us/step - loss: 0.1972\n",
      "Epoch 6/20\n",
      "3000/3000 [==============================] - 0s 65us/step - loss: 0.1974\n",
      "Epoch 7/20\n",
      "3000/3000 [==============================] - 0s 71us/step - loss: 0.1974\n",
      "Epoch 8/20\n",
      "3000/3000 [==============================] - 0s 105us/step - loss: 0.1972\n",
      "Epoch 9/20\n",
      "3000/3000 [==============================] - 0s 82us/step - loss: 0.1973\n",
      "Epoch 10/20\n",
      "3000/3000 [==============================] - 0s 82us/step - loss: 0.1973\n",
      "Epoch 11/20\n",
      "3000/3000 [==============================] - 0s 65us/step - loss: 0.1971\n",
      "Epoch 12/20\n",
      "3000/3000 [==============================] - 0s 59us/step - loss: 0.1972\n",
      "Epoch 13/20\n",
      "3000/3000 [==============================] - 0s 83us/step - loss: 0.1972\n",
      "Epoch 14/20\n",
      "3000/3000 [==============================] - 0s 62us/step - loss: 0.1973\n",
      "Epoch 15/20\n",
      "3000/3000 [==============================] - 0s 54us/step - loss: 0.1969\n",
      "Epoch 16/20\n",
      "3000/3000 [==============================] - 0s 57us/step - loss: 0.1972\n",
      "Epoch 17/20\n",
      "3000/3000 [==============================] - 0s 54us/step - loss: 0.1974\n",
      "Epoch 18/20\n",
      "3000/3000 [==============================] - 0s 60us/step - loss: 0.1972\n",
      "Epoch 19/20\n",
      "3000/3000 [==============================] - 0s 56us/step - loss: 0.1971\n",
      "Epoch 20/20\n",
      "3000/3000 [==============================] - 0s 59us/step - loss: 0.1972\n",
      "\n",
      "Model accuracy with epochs = 20, batch_size = 20\n",
      "\ttrain accuracy: 78.83333333333333 %\n",
      "\ttest accuracy: 77.3 %\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "batch_size = 20\n",
    "\n",
    "predict(epochs, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "3000/3000 [==============================] - 0s 58us/step - loss: 0.1971\n",
      "Epoch 2/30\n",
      "3000/3000 [==============================] - 0s 50us/step - loss: 0.1973\n",
      "Epoch 3/30\n",
      "3000/3000 [==============================] - 0s 52us/step - loss: 0.1972\n",
      "Epoch 4/30\n",
      "3000/3000 [==============================] - 0s 50us/step - loss: 0.1972\n",
      "Epoch 5/30\n",
      "3000/3000 [==============================] - 0s 52us/step - loss: 0.1974\n",
      "Epoch 6/30\n",
      "3000/3000 [==============================] - 0s 52us/step - loss: 0.1973\n",
      "Epoch 7/30\n",
      "3000/3000 [==============================] - 0s 53us/step - loss: 0.1972\n",
      "Epoch 8/30\n",
      "3000/3000 [==============================] - 0s 53us/step - loss: 0.1972\n",
      "Epoch 9/30\n",
      "3000/3000 [==============================] - 0s 63us/step - loss: 0.1971\n",
      "Epoch 10/30\n",
      "3000/3000 [==============================] - 0s 71us/step - loss: 0.1968\n",
      "Epoch 11/30\n",
      "3000/3000 [==============================] - 0s 54us/step - loss: 0.1974\n",
      "Epoch 12/30\n",
      "3000/3000 [==============================] - 0s 60us/step - loss: 0.1972\n",
      "Epoch 13/30\n",
      "3000/3000 [==============================] - 0s 78us/step - loss: 0.1971\n",
      "Epoch 14/30\n",
      "3000/3000 [==============================] - 0s 76us/step - loss: 0.1973\n",
      "Epoch 15/30\n",
      "3000/3000 [==============================] - 0s 53us/step - loss: 0.1971\n",
      "Epoch 16/30\n",
      "3000/3000 [==============================] - 0s 58us/step - loss: 0.1973\n",
      "Epoch 17/30\n",
      "3000/3000 [==============================] - 0s 53us/step - loss: 0.1972\n",
      "Epoch 18/30\n",
      "3000/3000 [==============================] - 0s 82us/step - loss: 0.1972\n",
      "Epoch 19/30\n",
      "3000/3000 [==============================] - 0s 77us/step - loss: 0.1971\n",
      "Epoch 20/30\n",
      "3000/3000 [==============================] - 0s 55us/step - loss: 0.1974\n",
      "Epoch 21/30\n",
      "3000/3000 [==============================] - 0s 59us/step - loss: 0.1975\n",
      "Epoch 22/30\n",
      "3000/3000 [==============================] - 0s 59us/step - loss: 0.1974\n",
      "Epoch 23/30\n",
      "3000/3000 [==============================] - 0s 79us/step - loss: 0.1973\n",
      "Epoch 24/30\n",
      "3000/3000 [==============================] - 0s 74us/step - loss: 0.1974\n",
      "Epoch 25/30\n",
      "3000/3000 [==============================] - 0s 55us/step - loss: 0.1972\n",
      "Epoch 26/30\n",
      "3000/3000 [==============================] - 0s 60us/step - loss: 0.1972\n",
      "Epoch 27/30\n",
      "3000/3000 [==============================] - 0s 57us/step - loss: 0.1971\n",
      "Epoch 28/30\n",
      "3000/3000 [==============================] - 0s 80us/step - loss: 0.1972\n",
      "Epoch 29/30\n",
      "3000/3000 [==============================] - 0s 69us/step - loss: 0.1971\n",
      "Epoch 30/30\n",
      "3000/3000 [==============================] - 0s 59us/step - loss: 0.1972\n",
      "\n",
      "Model accuracy with epochs = 30, batch_size = 20\n",
      "\ttrain accuracy: 79.53333333333333 %\n",
      "\ttest accuracy: 77.7 %\n"
     ]
    }
   ],
   "source": [
    "epochs = 30\n",
    "batch_size = 20\n",
    "\n",
    "predict(epochs, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
